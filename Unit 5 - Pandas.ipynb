{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Tables have Turned\n",
    "\n",
    "Pandas is an open-source Python library providing high-performance data manipulation and analysis tool using its powerful data structures. The name Pandas is derived from the term \"panel data\"â€”multi-dimensional data involving measurements over time (especially in statistics and econometrics). Using Pandas, we can accomplish 5 typical steps in the processing of data: loading, preparation, manipulation, modeling, and analysis.\n",
    "\n",
    "In addition to this notebook, many other resources are available:\n",
    "\n",
    "\n",
    "- [The docs](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Official (10 min) tutorial](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)\n",
    "- [Pandas tutorial for data science](https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/)\n",
    "- [Introduction to pandas](https://www.tutorialspoint.com/python_pandas/python_pandas_introduction.html)\n",
    "- [Examples cookbook](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#cookbook)\n",
    "- [Python Data Science Handbook & GitHub](https://github.com/jakevdp/PythonDataScienceHandbook)\n",
    "- [PyVideo](https://pyvideo.org/search?q=pandas)\n",
    "- [Reading a .csv file](https://honingds.com/blog/pandas-read_csv/)\n",
    "- [Pivot tables](http://pbpython.com/pandas-pivot-table-explained.html)\n",
    "- [Tricks](https://towardsdatascience.com/10-python-pandas-tricks-that-make-your-work-more-efficient-2e8e483808ba)\n",
    "\n",
    "Also see the \"Pandas Cheat Sheet\" in the Assets folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-structures\" data-toc-modified-id=\"Data-structures-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data structures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series\" data-toc-modified-id=\"Series-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Series</a></span><ul class=\"toc-item\"><li><span><a href=\"#Indexing-a-Series\" data-toc-modified-id=\"Indexing-a-Series-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Indexing a Series</a></span></li></ul></li><li><span><a href=\"#DataFrames\" data-toc-modified-id=\"DataFrames-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>DataFrames</a></span><ul class=\"toc-item\"><li><span><a href=\"#Indexing-a-DataFrame\" data-toc-modified-id=\"Indexing-a-DataFrame-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Indexing a DataFrame</a></span></li><li><span><a href=\"#Column-operations\" data-toc-modified-id=\"Column-operations-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Column operations</a></span></li><li><span><a href=\"#Row-operations\" data-toc-modified-id=\"Row-operations-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Row operations</a></span></li></ul></li><li><span><a href=\"#Panel-data\" data-toc-modified-id=\"Panel-data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Panel data</a></span></li></ul></li><li><span><a href=\"#IO-Tools\" data-toc-modified-id=\"IO-Tools-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>IO Tools</a></span><ul class=\"toc-item\"><li><span><a href=\"#Excel-spreadsheets\" data-toc-modified-id=\"Excel-spreadsheets-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Excel spreadsheets</a></span></li><li><span><a href=\"#Column-calculations\" data-toc-modified-id=\"Column-calculations-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Column calculations</a></span></li><li><span><a href=\"#Smoothing-data\" data-toc-modified-id=\"Smoothing-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Smoothing data</a></span></li><li><span><a href=\"#Data-type-issues\" data-toc-modified-id=\"Data-type-issues-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Data type issues</a></span></li></ul></li><li><span><a href=\"#Statistics\" data-toc-modified-id=\"Statistics-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descriptive-statistics\" data-toc-modified-id=\"Descriptive-statistics-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Descriptive statistics</a></span></li><li><span><a href=\"#Built-in-plots\" data-toc-modified-id=\"Built-in-plots-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Built-in plots</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was written for Pandas version 0.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures\n",
    "\n",
    "Pandas works with the following 3 data structures (built on top of the NumPy array):\n",
    "- Series (1D)\n",
    "- DataFrame (2D)\n",
    "- Multi-level DataFrames (3D)\n",
    "\n",
    "All Pandas data structures are value mutable (changeable) and, excluding Series, all are size mutable. \n",
    "\n",
    "### Series\n",
    "\n",
    "A series can be thought of as a single column of data in a table. Homogenous data can be structured with `pd.Series(data, index, dtype, copy)`. A series can be created from the built-in data sequences, ndarrays, or even scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(['a','b','c','d']) # the data is an array of strings\n",
    "pd.Series(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **optional** keyword arguments for `pd.Series` include `index` and `dtype` which allows you to specify custom index values and the data type, respectively. \n",
    "\n",
    "The data types (dtypes) are listed [here](https://docs.scipy.org/doc/numpy-1.10.4/user/basics.types.html). \n",
    "Some examples include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|dtype      |Description         |\n",
    "| ---       | --- |\n",
    "| int8\t    | Byte (-128 to 127)|\n",
    "| int32\t    | Integer (-2147483648 to 2147483647)|\n",
    "| float32\t| Single precision float (sign bit, 8 bits exponent, 23 bits mantissa)|\n",
    "| complex64\t| Complex number (two 32-bit floats which are the real and imaginary components)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison to the NumPy array, the pandas Series has an explicitly defined index associated with the values, which needn't be in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is a list of floats\n",
    "data = [6.0, 7.0, 8.0, 9.0]                                   \n",
    "s = pd.Series(data, index=[100, 101, 200, 201], dtype='int8') # change the data to integers\n",
    "print(s)\n",
    "print('')\n",
    "print(s.axes) # returns a list of the row axis labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is a dictionary\n",
    "data = {'a': 20, 'b': 40, 'c': 60} \n",
    "pd.Series(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: index order is persisted and the missing element is filled with NaN (Not a Number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'a': 0., 'b': 1., 'c': 2.}\n",
    "s = pd.Series(data, index=['b', 'c', 'd', 'a'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing a Series\n",
    "\n",
    "Both the explicitly defined (label-based) and implicitly defined (integer-based) indices can be used for indexing and slicing a Series. \n",
    "\n",
    "<span style=\"color:red\"> **Warning:** </span> When slicing with a label-based index (*i.e.*, `s['a':'c']`), the final index is included in the slice, while when slicing with integers (*i.e.*, `s[0:2]`), the final index is excluded from the slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [6, 7, 8, 9]                                   \n",
    "s = pd.Series(data, index=['a', 'b', 'c', 'd'])\n",
    "print(s['b'], 'is the same as', s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These slicing and indexing conventions can be a source of confusion. For example, if your Series has a label-based integer index, a \"normal\" indexing operation will use the **label-based indices**, while a slicing operation will use the **implicit indeces**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, it is recommended to use the specific *indexer* attribute required:\n",
    "\n",
    "- `loc`: explicit/label-based index (contrary to usual python slices, **both** the start and the stop are included)\n",
    "- `iloc`: implicit/integer index\n",
    "\n",
    "(Note that the `ix` indexer has been deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
    "s.loc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "\n",
    "DataFrames (tables) can be created with `pd.DataFrame(data, index, columns, dtype, copy)`, where the data can be built-in data sequences, ndarrays, Series or another DataFrame. Note, using `print()` will disable the pretty rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested lists for rows\n",
    "data = [['Alex', 10.0], \n",
    "        ['Bob', 12.0], \n",
    "        ['Clark', 13.0]]\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'], dtype='int8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary keys become the headings and the values are the data points\n",
    "data = {'Name':['Tom', 'Jack', 'Steve'], 'Age':[28, 34, 29]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing a DataFrame\n",
    "\n",
    "Columns can be accessed *via* dictionary-style indexing or attribute-style access. \n",
    "\n",
    "<span style=\"color:red\"> **Warning:** </span> The attribute-style referencing won't work if column names are not strings, have spaces, or conflict with methods of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `values` attribute gives a single indexable array of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display values greater than or equal to 30\n",
    "df[df['Age'] >= 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `loc` indexer we can index the underlying data in an array-like style but using the explicit index and column names. Using the `iloc` indexer, we can index the underlying array as if it is a simple NumPy array (using the implicit Python-style index), but the DataFrame index and column labels are maintained in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, index=['Overseer', 'Supervisor', 'Coordinator'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Overseer':'Supervisor', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows, columns\n",
    "df.iloc[0:2, 1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column operations\n",
    "\n",
    "Columns can be appended, added together, or deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series for columns\n",
    "d = {'col1': pd.Series([3, 6, 9], index=['ra', 'rb', 'rc']),\n",
    "     'col2': pd.Series([2, 4, 6, 8], index=['ra', 'rb', 'rc', 'rd'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# append a 3rd column\n",
    "df['col3'] = pd.Series([10, 20, 30], index=['ra','rb','rc'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column 1 & 3 together\n",
    "df['col4'] = df['col1'] + df['col3']\n",
    "print(df)\n",
    "print(\"\")\n",
    "\n",
    "# delete column 1\n",
    "df.pop('col1') # or, del df['col1']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row operations\n",
    "\n",
    "Row addition and deletion is also possible. Iteratively appending rows to a DataFrame is more computationally intensive than a single concatenate. Thus it is recommended to append those rows to a list and then **concatenate** the list with the original DataFrame all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'col1': pd.Series([3, 6, 9], index=['ra', 'rb', 'rc']),\n",
    "     'col2': pd.Series([10, 20, 30], index=['ra', 'rb', 'rc'])}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# Add row rd and re\n",
    "df2 = pd.DataFrame([[12, 40]], index = ['rd'], columns=['col1', 'col2'])\n",
    "df3 = pd.DataFrame([[15, 50]], index = ['re'], columns=['col1', 'col2'])\n",
    "df = df.append(df2)\n",
    "df = pd.concat([df, df3])\n",
    "\n",
    "# Delete row rc\n",
    "df = df.drop('rc')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add row re to row ra\n",
    "df.loc['ra'] += df.loc['re']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indices are aligned when performing operations on DataFrames. The following table lists Python operators and their equivalent Pandas object methods:\n",
    "\n",
    "| Python Operator | Pandas Method(s)                      |\n",
    "|-----------------|---------------------------------------|\n",
    "| ``+``           | ``add()``                             |\n",
    "| ``-``           | ``sub()``, ``subtract()``             |\n",
    "| ``*``           | ``mul()``, ``multiply()``             |\n",
    "| ``/``           | ``truediv()``, ``div()``, ``divide()``|\n",
    "| ``//``          | ``floordiv()``                        |\n",
    "| ``%``           | ``mod()``                             |\n",
    "| ``**``          | ``pow()``                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.add(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel data\n",
    "\n",
    "The official panel data type is being removed. Thus rather use the `MultiIndex` type within the DataFrame function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 2, 3, 4, 5],\n",
    "                 [6, 7, 8, 9, 0],\n",
    "                 [2, 4, 6, 8, 0],\n",
    "                 [1, 3, 5, 7, 9],\n",
    "                 [1, 1, 1, 1, 1],\n",
    "                 [8, 4, 7, 8, 6]])\n",
    "\n",
    "df = pd.DataFrame(data = data,\n",
    "    index = pd.MultiIndex.from_product([[2017, 2018, 2019], ['US', 'UK']]),\n",
    "    columns = ['col {}'.format(i) for i in range(1, 6)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:4, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO Tools\n",
    "\n",
    "The Pandas Input/Output API supports _reading from_ and _writing to_ [several different file formats](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) such as the following:\n",
    "\n",
    "| Data Description | Reader         | Writer       |\n",
    "|------------------|----------------|--------------|\n",
    "| CSV              | read_csv       | to_csv       |\n",
    "| JSON             | read_json      | to_json      |\n",
    "| HTML             | read_html      | to_html      |\n",
    "| Local clipboard  | read_clipboard | to_clipboard |\n",
    "| MS Excel         | read_excel     | to_excel     |\n",
    "\n",
    "\n",
    "Try highlighting the aforementioned table and press copy (or Ctrl+C), then run this cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel spreadsheets\n",
    "\n",
    "MS Excel is commonly used for data analysis. In a spreadsheet the emphasis is on the data, with the formulae remaining in the background, whereas in Python it's the other way around. It is good practice to separate your raw data from your calculations so that you don't accidentally overwrite it. \n",
    "\n",
    "Spreadsheets can be imported by pandas using the filename. If no `sheet_name` is specified, all sheets will be imported. To skip the first row after the heading, use `skiprows=[1]` as a keyword argument; however, this should not be necessary for tidy data.\n",
    "\n",
    "For illustrative purposes, the attached data files under Assets will be used. \"Experimental data.xlsx\" represents material tests performed on biopolymer (zein) films. The first sheet contains a description of the data and the units, with the following sheets containing data in dedicated tables with **one observation per row**. XRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_excel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perm = pd.read_excel('Assets/Experimental data.xlsx', sheet_name='Permeability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column calculations\n",
    "\n",
    "The first sheet shows the cummlative mass loss of diffusion cells containing one of 3 types of films wedged over an essential oil. We can create individual objects for each of these columns. Use the `head()` attribute to display the first 5 data points in a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df_perm['t_cum']\n",
    "ctrl = df_perm['Control']\n",
    "A1 = df_perm['A1']\n",
    "A2 = df_perm['A2']\n",
    "A3 = df_perm['A3']\n",
    "\n",
    "time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time, A1, 'o', label='A1')\n",
    "plt.plot(time, A2, 'o', label='A2')\n",
    "plt.plot(time, A3, 'o', label='A3')\n",
    "plt.ylabel('Cummulative mass loss (g)')\n",
    "plt.xlabel('Time (h)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the mass loss doesn't increase linearly. We can calculate:\n",
    "- the percent change between successive data points,\n",
    "- rank them in ascending order,\n",
    "- and find the correlation of the variables with respect to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_perm.pct_change().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perm.rank().head(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perm.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation matrix it is clear that film A3 had the least correlation with both time and the controlled experiment.\n",
    "\n",
    "We can also perform array-like calculations on the columns (_broadcasting_). For instance, let's express the time in days and the mass loss as a percentage (all cells had 30 g of oil initially). We simply divide the time column by 24 and the mass loss columns (A1 to A3) by 30. \n",
    "\n",
    "<span style=\"color:red\"> **Warning:** </span> If you're looping over columns, you're probably making more work for yourself than necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_d = time/24\n",
    "\n",
    "film_perm = df_perm.loc[0::1, 'A1':'A3']\n",
    "film_perm = film_perm/30*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_d, film_perm, 'o')\n",
    "plt.ylabel('Cummulative mass loss (%)')\n",
    "plt.xlabel('Time (days)')\n",
    "plt.legend(['A1', 'A2', 'A3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing data\n",
    "\n",
    "Sometimes noisy (\"spiky\") data are encountered, especially in timeseries. You can use moving/rolling average smoothing to see the trend better. The `rolling()` function will group observations into a window, and the `mean` method will calculate the average over a window, and place that as the new data point in the center spot (if `center=True`). Note this means that a (window - 1) number of datapoints will be lost on the sides of the plot and peaks may be flattened. \n",
    "\n",
    "Let's try it out on the X-ray diffraction (XRD) data. A window of 200 gives satisfactory smoothing. The first point in the smoothed data set is used to normalise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filelist = os.listdir('Assets/XRD-data')\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for file in filelist:\n",
    "    df = pd.read_excel('Assets/XRD-data/'+file, header=None)\n",
    "    df.columns = [\"wavelength\", \"intensity\"]\n",
    "    wl = df['wavelength']\n",
    "    it = df['intensity']\n",
    "    \n",
    "    it_smooth = it.rolling(window=200, center=True).mean()\n",
    "    df['smooth'] = it_smooth\n",
    "    factor = int(it_smooth.dropna().head(n=1))\n",
    "\n",
    "    plt.plot(wl, it/factor, label='Raw', alpha=0.3)\n",
    "    plt.plot(wl, it_smooth/factor, label='{}'.format(file[5:11]))\n",
    "plt.xlabel('2Î¸ (Â°)')\n",
    "plt.ylabel('Normalised intensity (â€”)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type issues\n",
    "\n",
    "Unfortunately, blindly doing operations on data without converting to the correct `dtype` will result in errors, as illustrated [here](https://pbpython.com/pandas_dtypes.html).\n",
    "\n",
    "In particular ensure that:\n",
    "\n",
    "- integers aren't stored as floats\n",
    "- values stored with units (e.g. prices or salaries) aren't stored as text\n",
    "- dates must be `datetime64`\n",
    "- binary values (yes or no) must be boolean\n",
    "\n",
    "You can check the `dtypes` using `df.info()` and convert them using the `df.astype()` attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "### Descriptive statistics\n",
    "\n",
    "A summary of statistics can be displayed for an entire DataFrame. Firstly, let's use the following data and organise it to see the trend better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Name':pd.Series(['Tom','James','Ricky','Vin','Steve','Johan','Jack',\n",
    "   'Lee','David','Helen','Brandon','Brandon']),\n",
    "   'Age':pd.Series([25,26,25,23,30,29,23,34,40,30,46,51]),\n",
    "   'Score':pd.Series([2.23,3.24,3.98,4.56,3.20,4.6,3.8,3.78,3.98,4.80,4.10,3.65])}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df.sort_values(by=['Age', 'Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df.describe()` attribute gives more statistical information. For numerical data the number of data points (count) and quartile values are shown. When including textual data in the description, repeated strings are regarded as \"non-unique\", with the most frequent string displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default only analyses numeric columns\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also obtain the sum and mode of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.mode())\n",
    "print(\"\")\n",
    "print(df.loc[:,\"Age\"].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in plots\n",
    "\n",
    "For quick visualisation, the built-in Pandas plotting attributes can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = df.hist(bins=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation\n",
    "\n",
    "McKinney, W (2010) \"Data structures for statistical computing in Python\", paper presented at the Proceedings of the 9th Python in Science Conference, 51â€“56.\n",
    "\n",
    "[(Publisher link)](http://conference.scipy.org/proceedings/scipy2010/mckinney.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
